# -*- coding: utf-8 -*-
"""SonDenemeler.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19x1FeWR8BZ3sWyZqbRuUR8msEuL1RXzm
"""

from google.colab import drive
drive.mount("/content/drive")

"""# Model 1"""

from __future__ import print_function
import numpy as np # For numerical fast numerical calculations
import matplotlib.pyplot as plt # For making plots
import pandas as pd # Deals with data
import seaborn as sns # Makes beautiful plots
import keras 
import sys 
from pandas import pandas as pd
#from sklearn.preprocessing import CategoricalEncoder as ce #import category_encoders as ce
import datetime
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import RMSprop
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
import os
import glob
import numpy as np
import scipy as sp
import pandas as pd
# skimage
from skimage.io import imshow, imread, imsave
from skimage.transform import rotate, AffineTransform, warp,rescale, resize, downscale_local_mean
from skimage import color,data
from skimage.exposure import adjust_gamma
from skimage.util import random_noise
# imgaug
import imageio
import imgaug as ia
import imgaug.augmenters as iaa
# Albumentations
import albumentations as A 
# Keras
from keras.preprocessing.image import ImageDataGenerator,array_to_img, img_to_array, load_img 
#visualisation
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
#%matplotlib inline
import seaborn as sns
from IPython.display import HTML, Image
import cv2
import os
import matplotlib.ticker as ticker
import matplotlib.pyplot as plt
import seaborn as sns

# load data

#p_train=pd.read_csv('/content/drive/MyDrive/Plant_Pathology_2020/train.csv')
#p_test=pd.read_csv('/content/drive/MyDrive/Plant_Pathology_2020/test.csv')

import numpy as np # For numerical fast numerical calculations
#import matplotlib.pyplot as plt # For making plots
import pandas as pd # Deals with data
#import seaborn as sns # Makes beautiful plots
import keras 
#import sys 
#from pandas import pandas as pd
#from sklearn.preprocessing import CategoricalEncoder as ce #import category_encoders as ce
#import datetime
from keras.models import Sequential
#from keras.layers import Dense, Dropout
from keras.optimizers import RMSprop
from sklearn.model_selection import train_test_split

from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D
from keras.layers import Dense, Activation, Dropout, Flatten

from keras.preprocessing import image
#from keras.preprocessing.image import ImageDataGenerator
import keras.optimizers

from tensorflow.python.keras.optimizer_v2.adam import Adam

#from sklearn.svm import SVC
import os
import glob
#import numpy as np
#import scipy as sp
#import pandas as pd
# skimage
from skimage.io import imshow, imread, imsave
#from skimage.transform import rotate, AffineTransform, warp,rescale, resize, downscale_local_mean
#from skimage import color,data
#from skimage.exposure import adjust_gamma
#from skimage.util import random_noise
# imgaug
#import imageio
#import imgaug as ia
#import imgaug.augmenters as iaa
# Albumentations
#import albumentations as A 
# Keras
from keras.preprocessing.image import ImageDataGenerator,array_to_img, img_to_array, load_img 
#visualisation
import matplotlib.pyplot as plt
#import matplotlib.image as mpimg
#%matplotlib inline
#import seaborn as sns
#from IPython.display import HTML, Image
import cv2

p_train=pd.read_csv('/content/drive/MyDrive/Plant_Pathology_2020/train.csv')
p_test=pd.read_csv('/content/drive/MyDrive/Plant_Pathology_2020/test.csv')

target = p_train[['healthy', 'multiple_diseases', 'rust', 'scab']]
test_ids = p_test['image_id']

img_size=224

# Direkt görüntüleri listeye aktarmış oluyoruz

train_image=[]
for name in p_train['image_id']:
    path='/content/drive/MyDrive/Plant_Pathology_2020/images/'+name+'.jpg'
    img=cv2.imread(path)
    image=cv2.resize(img,(img_size,img_size),interpolation=cv2.INTER_AREA)
    train_image.append(image)

fig, ax = plt.subplots(1, 4, figsize=(15, 15))
for i in range(4):
    ax[i].set_axis_off()
    ax[i].imshow(train_image[i])
    
    
test_image=[]
for name in p_test['image_id']:
    path='/content/drive/MyDrive/Plant_Pathology_2020/test_images/'+name+'.jpg'
    img=cv2.imread(path)
    image=cv2.resize(img,(img_size,img_size),interpolation=cv2.INTER_AREA)
    test_image.append(image)

fig, ax = plt.subplots(1, 4, figsize=(15, 15))
for i in range(4):
    ax[i].set_axis_off()
    ax[i].imshow(test_image[i])

#sorted_data.to_csv ('/content/drive/MyDrive/Plant_Pathology_2020/merge_data.csv', index = False, header=True)
#csv_pandas = pd.DataFrame(train_image)
#csv_pandas.to_csv ('/content/drive/MyDrive/Plant_Pathology_2020/train_image.csv', index = False, header=True)
#csv_pandas = pd.DataFrame(test_image)
#csv_pandas.to_csv ('/content/drive/MyDrive/Plant_Pathology_2020/test_image.csv', index = False, header=True)

print(train_image[0].shape)
print(type(train_image[0]))

a = np.array(train_image)
print(a.shape)

#YAPMA
#from keras.preprocessing.image import img_to_array

#x_train = np.ndarray(shape=(len(train_image), img_size, img_size, 3),dtype = np.float32)
#i=0
#for image in train_image:
#    x_train[i]=img_to_array(image)
#    x_train[i]=train_image[i]
#    i=i+1
#x_train=x_train/255
#print('Train Shape: {}'.format(x_train.shape))

#YAPMA
#Burada ise görüntüleri arraylere çeviriyoruz

#from keras.preprocessing.image import img_to_array

#x_train = np.ndarray(shape=(len(train_image), img_size, img_size, 3),dtype = np.float32)
#i=0
#for image in train_image:
#    x_train[i]=img_to_array(image)
#    x_train[i]=train_image[i]
#    i=i+1
#x_train=x_train/255
#print('Train Shape: {}'.format(x_train.shape))######

#x_test = np.ndarray(shape=(len(test_image), img_size, img_size, 3),dtype = np.float32)
#i=0
#for image in test_image:
#    x_test[i]=img_to_array(image)
#    x_test[i]=test_image[i]
#    i=i+1
    
#x_test=x_test/255
#print('Test Shape: {}'.format(x_test.shape))

#listeden arraye dönüştürüyoruz

#x_train = np.ndarray(train_image) # bu şekilde olmuyor
#x_test = np.ndarray(test_image)
x_train = np.ndarray(shape=(len(train_image), img_size, img_size, 3),dtype = np.float32)
i=0
for image in train_image:
    x_train[i]=img_to_array(image)
    x_train[i]=train_image[i]
    i=i+1
x_train=x_train/255 # scale
print('Train Shape: {}'.format(x_train.shape))

x_train[0]

x_test = np.ndarray(shape=(len(test_image), img_size, img_size, 3),dtype = np.float32)
i=0
for image in test_image:
    x_test[i]=img_to_array(image)
    x_test[i]=test_image[i]
    i=i+1
    
x_test=x_test/255 # scale
print('Test Shape: {}'.format(x_test.shape))

x_test[0]

y = p_train.copy()
del y['image_id'] # image_id kolonunu sildik
y.head()

y_train = np.array(y.values)
print(y_train.shape,y_train[0])

from sklearn.model_selection import train_test_split

x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)

x_train.shape, x_val.shape, y_train.shape, y_val.shape

#YAPMA
#from imblearn.over_sampling import SMOTE 

#sm = SMOTE(random_state = 115) 
 
#a_train, b_train = sm.fit_resample(x_train.reshape((-1, img_size * img_size * 3)), y_train)
#a_train = a_train.reshape((-1, img_size, img_size, 3))
#x_train.shape, y_train.sum(axis=0)
#a_train.shape, b_train.shape

#a_train[0].shape

from keras.callbacks import ReduceLROnPlateau
from keras.callbacks import EarlyStopping

LR_reduce=ReduceLROnPlateau(monitor='val_accuracy',
                            factor=.5,
                            patience=10,
                            min_lr=.000001,
                            verbose=1)

ES_monitor=EarlyStopping(monitor='val_loss',
                          patience=20)

#reg = .0005

#import keras
#from keras.models import Sequential
#from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D,Conv3D
#from keras.layers import Dense, Activation, Dropout, Flatten

#from keras.preprocessing import image
#from keras.preprocessing.image import ImageDataGenerator
#import keras.optimizers

#from tensorflow.python.keras.optimizer_v2.adam import Adam



#%%
#------------------------------
#Evrişimli Sinir Ağı Mimarisini Oluşturma
model2 = Sequential()

#1. evrişim katmanı
model2.add(Conv2D(128, (5, 5), activation='LeakyReLU', input_shape=(224,224,3))) 
model2.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))
#64den 128 

#2. Evrişim katmanı
model2.add(Conv2D(256, (3, 3), activation='LeakyReLU')) #128 den 256
model2.add(Conv2D(256, (3, 3), activation='LeakyReLU'))
#model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))
model2.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))



#3. Evrişim katmanı
model2.add(Conv2D(512, (3, 3), activation='LeakyReLU')) #256 dan 512
model2.add(Conv2D(512, (3, 3), activation='LeakyReLU'))
#model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))
model2.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))


model2.add(Flatten())

# Tam bağlantı katmanı
model2.add(Dense(1024, activation='LeakyReLU'))
#model2.add(Dropout(0.1))
model2.add(Dense(1024, activation='LeakyReLU'))
#model2.add(Dropout(0.1))

model2.add(Dense(1, activation='softmax')) #model.add(Dense(num_classes, activation='softmax'))
#------------------------------
model2.summary()

#------------------------------
opt = keras.optimizers.Adam(learning_rate=0.3)
#adam = Adam() #tf.keras.optimizers.Adam(learning_rate=0.1)
model2.compile(optimizer='rmsprop', 
              loss='categorical_crossentropy',
              metrics=['accuracy']
)

#------------------------------

#Batch (Küme) işlemleri
#gen = ImageDataGenerator()
#train_generator = gen.flow(X_train, y_train)#, batch_size=batch_size)

"""ImageDataGenerator, Keras'ın derin öğrenme için görüntü verilerinin ardışık düzenlenmesi için başvurduğu sınıftır. 
Yerel dosya sisteminize kolay erişim ve farklı yapılardan veri yüklemek için birden fazla farklı yöntem sağlar. 
Ayrıca oldukça güçlü veri ön işleme ve artırma yeteneklerine sahiptir"""

datagen = ImageDataGenerator(rotation_range=45,
                             shear_range=0.25,
                              zoom_range=0.25,
                              width_shift_range=0.25,
                              height_shift_range=0.25,
                              rescale=1/255,
                              brightness_range=[0.5,1.5],
                              horizontal_flip=True,
                              vertical_flip=True,
                              fill_mode='nearest'
#                              featurewise_center=True,
#                              samplewise_center=True,
#                              featurewise_std_normalization=True,
#                              samplewise_std_normalization=True,
#                              zca_whitening=True
                              )

from keras.callbacks import ModelCheckpoint

root = '/content/drive/MyDrive/Plant_Pathology_2020/'
# en başarılı ağırlıkları kaydet
checkpointer = ModelCheckpoint(filepath=root + 'data/face_model.h5', verbose=1, save_best_only=True)

history = model2.fit_generator(datagen.flow(x_train, y_train, batch_size=24), # train verileri için veri artırma
                              epochs=300,
                              steps_per_epoch=x_train.shape[0] // 24,
                              verbose=1,
                              callbacks=[ES_monitor,LR_reduce],
                              validation_data=datagen.flow(x_val, y_val,batch_size=24), # validation verileri için veri artırma
                              validation_steps=x_val.shape[0]//24
                              )

x_train[0]

x_test[0]

# save model to json
model_json = model2.to_json()
with open(root + "data/face_model.json", "w") as json_file:
    json_file.write(model_json)

from matplotlib import pyplot as plt

h = history.history

offset = 5
epochs = range(offset, len(h['loss']))

plt.figure(1, figsize=(20, 6))

plt.subplot(121)
plt.xlabel('epochs')
plt.ylabel('loss')
plt.plot(epochs, h['loss'][offset:], label='train')
plt.plot(epochs, h['val_loss'][offset:], label='val')
plt.legend()

plt.subplot(122)
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.plot(h[f'accuracy'], label='train')
plt.plot(h[f'val_accuracy'], label='val')
plt.legend()

plt.show()

from sklearn.metrics import roc_auc_score

pred_test = model2.predict(x_val)
roc_sum = 0
for i in range(4):
    score = roc_auc_score(y_val[:, i], pred_test[:, i])
    roc_sum += score
    print(f'{score:.3f}')

roc_sum /= 4
print(f'totally:{roc_sum:.3f}')

pred = model2.predict(x_test)

res = pd.DataFrame()
res['image_id'] = test_ids
res['healthy'] = pred[:, 0]
res['multiple_diseases'] = pred[:, 1]
res['rust'] = pred[:, 2]
res['scab'] = pred[:, 3]
res.to_csv('Mysubmission.csv', index=False)
res.head(10)

# en iyi ağırlıkları yükle
model2.load_weights(root + 'data/face_model.h5')

"""# MODEL 2"""

from keras.callbacks import ReduceLROnPlateau
from keras.callbacks import EarlyStopping

LR_reduce=ReduceLROnPlateau(monitor='val_accuracy',
                            factor=.5,
                            patience=10,
                            min_lr=.000001,
                            verbose=1)

ES_monitor=EarlyStopping(monitor='val_loss',
                          patience=20)

#import keras
#from keras.models import Sequential
#from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D,Conv3D
#from keras.layers import Dense, Activation, Dropout, Flatten

#from keras.preprocessing import image
#from keras.preprocessing.image import ImageDataGenerator
#import keras.optimizers

#from tensorflow.python.keras.optimizer_v2.adam import Adam



#%%
#------------------------------
#Evrişimli Sinir Ağı Mimarisini Oluşturma
model3 = Sequential()

#1. evrişim katmanı
model3.add(Conv2D(128, (5, 5), activation='ReLU', input_shape=(224,224,3))) 
model3.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))
#64den 128 

#2. Evrişim katmanı
model3.add(Conv2D(256, (3, 3), activation='ReLU')) #128 den 256
model3.add(Conv2D(256, (3, 3), activation='ReLU'))
#model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))
model3.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))



#3. Evrişim katmanı
model3.add(Conv2D(512, (3, 3), activation='ReLU')) #256 dan 512
model3.add(Conv2D(512, (3, 3), activation='ReLU'))
#model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))
model3.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))


model3.add(Flatten())

# Tam bağlantı katmanı
model3.add(Dense(1024, activation='ReLU'))
model3.add(Dropout(0.25))
model3.add(Dense(1024, activation='ReLU'))
model3.add(Dropout(0.25))

model3.add(Dense(1, activation='softmax')) #model.add(Dense(num_classes, activation='softmax'))
#------------------------------
model3.summary()

#------------------------------
#opt = keras.optimizers.Adam(learning_rate=0.3)
#adam = Adam() #tf.keras.optimizers.Adam(learning_rate=0.1)
model3.compile(optimizer='rmsprop', 
              loss='categorical_crossentropy',
              metrics=['accuracy']
)

#------------------------------

"""ImageDataGenerator, Keras'ın derin öğrenme için görüntü verilerinin ardışık düzenlenmesi için başvurduğu sınıftır. 
Yerel dosya sisteminize kolay erişim ve farklı yapılardan veri yüklemek için birden fazla farklı yöntem sağlar. 
Ayrıca oldukça güçlü veri ön işleme ve artırma yeteneklerine sahiptir"""

datagen = ImageDataGenerator(rotation_range=45,
                             shear_range=0.25,
                              zoom_range=0.25,
                              width_shift_range=0.25,
                              height_shift_range=0.25,
                              rescale=1/255,
                              brightness_range=[0.5,1.5],
                              horizontal_flip=True,
                              vertical_flip=True,
                              fill_mode='nearest'
#                              featurewise_center=True,
#                              samplewise_center=True,
#                              featurewise_std_normalization=True,
#                              samplewise_std_normalization=True,
#                              zca_whitening=True
                              )

from keras.callbacks import ModelCheckpoint

root = '/content/drive/MyDrive/Plant_Pathology_2020/'
# en başarılı ağırlıkları kaydet
checkpointer = ModelCheckpoint(filepath=root + 'plant_model.h5', verbose=1, save_best_only=True)



history = model3.fit_generator(datagen.flow(x_train, y_train, batch_size=24), # train verileri için veri artırma
                              epochs=300,
                              steps_per_epoch=x_train.shape[0] // 24,
                              verbose=1,
                              callbacks=[ES_monitor,LR_reduce],
                              validation_data=datagen.flow(x_val, y_val,batch_size=24), # validation verileri için veri artırma
                              validation_steps=x_val.shape[0]//24
                              )

# save model to json
model_json = model3.to_json()
with open(root + "plant_model.json", "w") as json_file:
    json_file.write(model_json)

x_train[0]

x_test[0]

from matplotlib import pyplot as plt

h = history.history

offset = 5
epochs = range(offset, len(h['loss']))

plt.figure(1, figsize=(20, 6))

plt.subplot(121)
plt.xlabel('epochs')
plt.ylabel('loss')
plt.plot(epochs, h['loss'][offset:], label='train')
plt.plot(epochs, h['val_loss'][offset:], label='val')
plt.legend()

plt.subplot(122)
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.plot(h[f'accuracy'], label='train')
plt.plot(h[f'val_accuracy'], label='val')
plt.legend()

plt.show()

from sklearn.metrics import roc_auc_score

print("ROC-AUC SCORE")
pred_test = model3.predict(x_val)
roc_sum = 0
for i in range(4):
    score = roc_auc_score(y_val[:, i], pred_test[:, i])
    roc_sum += score
    print(f'{score:.3f}')

roc_sum /= 4
print(f'totally:{roc_sum:.3f}')

pred = model3.predict(x_test)

res = pd.DataFrame()
res['image_id'] = test_ids
res['healthy'] = pred[:, 0]
res['multiple_diseases'] = pred[:, 1]
res['rust'] = pred[:, 2]
res['scab'] = pred[:, 3]
res.to_csv('Mysubmission2.csv', index=False)
res.head(10)



"""# MODEL 1 TEKRAR"""

from keras.callbacks import ReduceLROnPlateau
from keras.callbacks import EarlyStopping

LR_reduce=ReduceLROnPlateau(monitor='val_accuracy',
                            factor=.5,
                            patience=10,
                            min_lr=.000001,
                            verbose=1)

ES_monitor=EarlyStopping(monitor='val_loss',
                          patience=20)

#reg = .0005

#import keras
#from keras.models import Sequential
#from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D,Conv3D
#from keras.layers import Dense, Activation, Dropout, Flatten

#from keras.preprocessing import image
#from keras.preprocessing.image import ImageDataGenerator
#import keras.optimizers

#from tensorflow.python.keras.optimizer_v2.adam import Adam



#%%
#------------------------------
#Evrişimli Sinir Ağı Mimarisini Oluşturma
model2_2 = Sequential()

#1. evrişim katmanı
model2_2.add(Conv2D(128, (5, 5), activation='LeakyReLU', input_shape=(224,224,3))) 
model2_2.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))
#64den 128 

#2. Evrişim katmanı
model2_2.add(Conv2D(256, (3, 3), activation='LeakyReLU')) #128 den 256
model2_2.add(Conv2D(256, (3, 3), activation='LeakyReLU'))
#model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))
model2_2.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))



#3. Evrişim katmanı
model2_2.add(Conv2D(512, (3, 3), activation='LeakyReLU')) #256 dan 512
model2_2.add(Conv2D(512, (3, 3), activation='LeakyReLU'))
#model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))
model2_2.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))


model2_2.add(Flatten())

# Tam bağlantı katmanı
model2_2.add(Dense(1024, activation='LeakyReLU'))
#model2.add(Dropout(0.1))
model2_2.add(Dense(1024, activation='LeakyReLU'))
#model2.add(Dropout(0.1))

model2_2.add(Dense(1, activation='softmax')) #model.add(Dense(num_classes, activation='softmax'))
#------------------------------
model2_2.summary()

#------------------------------
#opt = keras.optimizers.Adam(learning_rate=0.3)
#adam = Adam() #tf.keras.optimizers.Adam(learning_rate=0.1)
model2_2.compile(optimizer='rmsprop', 
              loss='categorical_crossentropy',
              metrics=['accuracy']
)

#------------------------------

"""ImageDataGenerator, Keras'ın derin öğrenme için görüntü verilerinin ardışık düzenlenmesi için başvurduğu sınıftır. 
Yerel dosya sisteminize kolay erişim ve farklı yapılardan veri yüklemek için birden fazla farklı yöntem sağlar. 
Ayrıca oldukça güçlü veri ön işleme ve artırma yeteneklerine sahiptir"""

datagen = ImageDataGenerator(rotation_range=45,
                             shear_range=0.25,
                              zoom_range=0.25,
                              width_shift_range=0.25,
                              height_shift_range=0.25,
                              rescale=1/255,
                              brightness_range=[0.5,1.5],
                              horizontal_flip=True,
                              vertical_flip=True,
                              fill_mode='nearest'
#                              featurewise_center=True,
#                              samplewise_center=True,
#                              featurewise_std_normalization=True,
#                              samplewise_std_normalization=True,
#                              zca_whitening=True
                              )

from keras.callbacks import ModelCheckpoint

root = '/content/drive/MyDrive/Plant_Pathology_2020/'
# en başarılı ağırlıkları kaydet
checkpointer = ModelCheckpoint(filepath=root + 'data/plant_model2.h5', verbose=1, save_best_only=True)



history = model2_2.fit_generator(datagen.flow(x_train, y_train, batch_size=24), # train verileri için veri artırma
                              epochs=300,
                              steps_per_epoch=x_train.shape[0] // 24,
                              verbose=1,
                              callbacks=[ES_monitor,LR_reduce],
                              validation_data=datagen.flow(x_val, y_val,batch_size=24), # validation verileri için veri artırma
                              validation_steps=x_val.shape[0]//24
                              )

# save model to json
model_json = model2_2.to_json()
with open(root + "data/plant_model2.json", "w") as json_file:
    json_file.write(model_json)

x_train[0]

x_test[0]

from matplotlib import pyplot as plt

h = history.history

offset = 5
epochs = range(offset, len(h['loss']))

plt.figure(1, figsize=(20, 6))

plt.subplot(121)
plt.xlabel('epochs')
plt.ylabel('loss')
plt.plot(epochs, h['loss'][offset:], label='train')
plt.plot(epochs, h['val_loss'][offset:], label='val')
plt.legend()

plt.subplot(122)
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.plot(h[f'accuracy'], label='train')
plt.plot(h[f'val_accuracy'], label='val')
plt.legend()

plt.show()

from sklearn.metrics import roc_auc_score

pred_test = model2_2.predict(x_val)
roc_sum = 0
for i in range(4):
    score = roc_auc_score(y_val[:, i], pred_test[:, i])
    roc_sum += score
    print(f'{score:.3f}')

roc_sum /= 4
print(f'totally:{roc_sum:.3f}')

pred = model2_2.predict(x_test)

res = pd.DataFrame()
res['image_id'] = test_ids
res['healthy'] = pred[:, 0]
res['multiple_diseases'] = pred[:, 1]
res['rust'] = pred[:, 2]
res['scab'] = pred[:, 3]
res.to_csv('Mysubmission3.csv', index=False)
res.head(10)

